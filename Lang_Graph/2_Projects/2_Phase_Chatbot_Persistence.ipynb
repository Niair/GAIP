{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a36809f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver   # for taking back the conversation of the previous workflow, it save that in ram\n",
    "from typing import TypedDict, Annotated, Literal\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32df3def",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d0d7b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state\n",
    "class JokeState(TypedDict):\n",
    "\n",
    "      topic : str\n",
    "      joke : str\n",
    "      explanation : str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa1981fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def generate_joke(state : JokeState):\n",
    "\n",
    "      prompt = f\"generate a joke based on the topic : {state['topic']}\"\n",
    "      response = model.invoke(prompt)\n",
    "\n",
    "      return {\"joke\" : response}\n",
    "\n",
    "def generate_joke_explanation(state : JokeState):\n",
    "\n",
    "      prompt = f\"generate the explanation of this joke : {state['joke']}\"\n",
    "      response = model.invoke(prompt)\n",
    "\n",
    "      return {\"explanation\" : response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46dc9ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create graph\n",
    "graph = StateGraph(JokeState)\n",
    "\n",
    "# add_node\n",
    "graph.add_node(\"generate_joke\", generate_joke)\n",
    "graph.add_node(\"generate_joke_explanation\", generate_joke_explanation)\n",
    "\n",
    "# add edges\n",
    "graph.add_edge(START, \"generate_joke\")\n",
    "graph.add_edge(\"generate_joke\", \"generate_joke_explanation\")\n",
    "graph.add_edge(\"generate_joke_explanation\", END)\n",
    "\n",
    "# checkpointer\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# compile\n",
    "workflow = graph.compile(checkpointer = checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1124e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # thread\n",
    "# thread_id = 1\n",
    "\n",
    "# config\n",
    "config = {'configurable' : {'thread_id' : '1'}}\n",
    "\n",
    "# working\n",
    "initial_state = {\n",
    "      'topic' : \"Pizza\"\n",
    "}\n",
    "\n",
    "final_state = workflow.invoke(initial_state, config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dfe388a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'Pizza',\n",
       " 'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.027189206, 'completion_tokens_details': None, 'prompt_time': 0.002414078, 'prompt_tokens_details': None, 'queue_time': 0.055648052, 'total_time': 0.029603284}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b5469-b807-7a33-96dc-c7fbc0896e82-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64}),\n",
       " 'explanation': AIMessage(content='**Joke Explanation: \"Why did the pizza go to the doctor? Because it was feeling a little crusty.\"**\\n\\nThis joke is an example of a play on words, specifically a pun. A pun is a form of wordplay that exploits multiple meanings of a word or phrase, often to create a humorous effect.\\n\\nIn this joke, the word \"crusty\" has a double meaning:\\n\\n1. **Literal meaning**: A pizza crust is a hard, crunchy exterior that makes up the base of a pizza.\\n2. **Idiomatic meaning**: To be \"feeling a little crusty\" is an idiomatic expression that means to be feeling a bit grumpy, irritable, or out of sorts.\\n\\nThe joke relies on this double meaning to create a pun. The setup, \"Why did the pizza go to the doctor?\", primes the listener to expect a typical reason for visiting a doctor, such as illness or injury. However, the punchline subverts this expectation by using the word \"crusty\" in its idiomatic sense, implying that the pizza is feeling grumpy, rather than literally having a crusty exterior.\\n\\nThe humor in this joke comes from the unexpected twist on the word \"crusty\" and the clever use of language to create a pun.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 259, 'prompt_tokens': 260, 'total_tokens': 519, 'completion_time': 0.333008452, 'completion_tokens_details': None, 'prompt_time': 0.016038781, 'prompt_tokens_details': None, 'queue_time': 0.054638728, 'total_time': 0.349047233}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b5469-b8a6-7fe2-b54c-c58d3a9af534-0', usage_metadata={'input_tokens': 260, 'output_tokens': 259, 'total_tokens': 519})}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37ab44a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'Pizza', 'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.027189206, 'completion_tokens_details': None, 'prompt_time': 0.002414078, 'prompt_tokens_details': None, 'queue_time': 0.055648052, 'total_time': 0.029603284}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b5469-b807-7a33-96dc-c7fbc0896e82-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64}), 'explanation': AIMessage(content='**Joke Explanation: \"Why did the pizza go to the doctor? Because it was feeling a little crusty.\"**\\n\\nThis joke is an example of a play on words, specifically a pun. A pun is a form of wordplay that exploits multiple meanings of a word or phrase, often to create a humorous effect.\\n\\nIn this joke, the word \"crusty\" has a double meaning:\\n\\n1. **Literal meaning**: A pizza crust is a hard, crunchy exterior that makes up the base of a pizza.\\n2. **Idiomatic meaning**: To be \"feeling a little crusty\" is an idiomatic expression that means to be feeling a bit grumpy, irritable, or out of sorts.\\n\\nThe joke relies on this double meaning to create a pun. The setup, \"Why did the pizza go to the doctor?\", primes the listener to expect a typical reason for visiting a doctor, such as illness or injury. However, the punchline subverts this expectation by using the word \"crusty\" in its idiomatic sense, implying that the pizza is feeling grumpy, rather than literally having a crusty exterior.\\n\\nThe humor in this joke comes from the unexpected twist on the word \"crusty\" and the clever use of language to create a pun.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 259, 'prompt_tokens': 260, 'total_tokens': 519, 'completion_time': 0.333008452, 'completion_tokens_details': None, 'prompt_time': 0.016038781, 'prompt_tokens_details': None, 'queue_time': 0.054638728, 'total_time': 0.349047233}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b5469-b8a6-7fe2-b54c-c58d3a9af534-0', usage_metadata={'input_tokens': 260, 'output_tokens': 259, 'total_tokens': 519})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e1637-582f-67b8-8002-5b16fe7ff6cd'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-12-25T07:29:33.801464+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e1637-53e1-697e-8001-de028ecb6f3a'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state(config)  # this will show you the final state value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd137f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'Pizza', 'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.027189206, 'completion_tokens_details': None, 'prompt_time': 0.002414078, 'prompt_tokens_details': None, 'queue_time': 0.055648052, 'total_time': 0.029603284}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b5469-b807-7a33-96dc-c7fbc0896e82-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64}), 'explanation': AIMessage(content='**Joke Explanation: \"Why did the pizza go to the doctor? Because it was feeling a little crusty.\"**\\n\\nThis joke is an example of a play on words, specifically a pun. A pun is a form of wordplay that exploits multiple meanings of a word or phrase, often to create a humorous effect.\\n\\nIn this joke, the word \"crusty\" has a double meaning:\\n\\n1. **Literal meaning**: A pizza crust is a hard, crunchy exterior that makes up the base of a pizza.\\n2. **Idiomatic meaning**: To be \"feeling a little crusty\" is an idiomatic expression that means to be feeling a bit grumpy, irritable, or out of sorts.\\n\\nThe joke relies on this double meaning to create a pun. The setup, \"Why did the pizza go to the doctor?\", primes the listener to expect a typical reason for visiting a doctor, such as illness or injury. However, the punchline subverts this expectation by using the word \"crusty\" in its idiomatic sense, implying that the pizza is feeling grumpy, rather than literally having a crusty exterior.\\n\\nThe humor in this joke comes from the unexpected twist on the word \"crusty\" and the clever use of language to create a pun.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 259, 'prompt_tokens': 260, 'total_tokens': 519, 'completion_time': 0.333008452, 'completion_tokens_details': None, 'prompt_time': 0.016038781, 'prompt_tokens_details': None, 'queue_time': 0.054638728, 'total_time': 0.349047233}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b5469-b8a6-7fe2-b54c-c58d3a9af534-0', usage_metadata={'input_tokens': 260, 'output_tokens': 259, 'total_tokens': 519})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e1637-582f-67b8-8002-5b16fe7ff6cd'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-12-25T07:29:33.801464+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e1637-53e1-697e-8001-de028ecb6f3a'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'Pizza', 'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.027189206, 'completion_tokens_details': None, 'prompt_time': 0.002414078, 'prompt_tokens_details': None, 'queue_time': 0.055648052, 'total_time': 0.029603284}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b5469-b807-7a33-96dc-c7fbc0896e82-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64})}, next=('generate_joke_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e1637-53e1-697e-8001-de028ecb6f3a'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-12-25T07:29:33.350131+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e1637-525c-6d49-8000-7e75f2d875f4'}}, tasks=(PregelTask(id='774ae965-379b-d3b9-c559-f1ab4a1bbb53', name='generate_joke_explanation', path=('__pregel_pull', 'generate_joke_explanation'), error=None, interrupts=(), state=None, result={'explanation': AIMessage(content='**Joke Explanation: \"Why did the pizza go to the doctor? Because it was feeling a little crusty.\"**\\n\\nThis joke is an example of a play on words, specifically a pun. A pun is a form of wordplay that exploits multiple meanings of a word or phrase, often to create a humorous effect.\\n\\nIn this joke, the word \"crusty\" has a double meaning:\\n\\n1. **Literal meaning**: A pizza crust is a hard, crunchy exterior that makes up the base of a pizza.\\n2. **Idiomatic meaning**: To be \"feeling a little crusty\" is an idiomatic expression that means to be feeling a bit grumpy, irritable, or out of sorts.\\n\\nThe joke relies on this double meaning to create a pun. The setup, \"Why did the pizza go to the doctor?\", primes the listener to expect a typical reason for visiting a doctor, such as illness or injury. However, the punchline subverts this expectation by using the word \"crusty\" in its idiomatic sense, implying that the pizza is feeling grumpy, rather than literally having a crusty exterior.\\n\\nThe humor in this joke comes from the unexpected twist on the word \"crusty\" and the clever use of language to create a pun.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 259, 'prompt_tokens': 260, 'total_tokens': 519, 'completion_time': 0.333008452, 'completion_tokens_details': None, 'prompt_time': 0.016038781, 'prompt_tokens_details': None, 'queue_time': 0.054638728, 'total_time': 0.349047233}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b5469-b8a6-7fe2-b54c-c58d3a9af534-0', usage_metadata={'input_tokens': 260, 'output_tokens': 259, 'total_tokens': 519})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'Pizza'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e1637-525c-6d49-8000-7e75f2d875f4'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-12-25T07:29:33.190893+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e1637-525a-662b-bfff-ab1c762d5779'}}, tasks=(PregelTask(id='b87f6829-513e-5143-ee7e-3d54829a3329', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.027189206, 'completion_tokens_details': None, 'prompt_time': 0.002414078, 'prompt_tokens_details': None, 'queue_time': 0.055648052, 'total_time': 0.029603284}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b5469-b807-7a33-96dc-c7fbc0896e82-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e1637-525a-662b-bfff-ab1c762d5779'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-12-25T07:29:33.189892+00:00', parent_config=None, tasks=(PregelTask(id='7efd4100-9877-4025-c3f4-b928d8fc1eff', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'Pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config))  # code to check all the intermediate value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89f80e89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'Pasta',\n",
       " 'joke': AIMessage(content='Why did the spaghetti go to therapy? \\n\\nBecause it was feeling a little \"twisted\" and wanted to untangle its emotions.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 44, 'total_tokens': 72, 'completion_time': 0.032505874, 'completion_tokens_details': None, 'prompt_time': 0.002671357, 'prompt_tokens_details': None, 'queue_time': 0.050628543, 'total_time': 0.035177231}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b546c-be47-7e31-ade4-59dcc1ecebe7-0', usage_metadata={'input_tokens': 44, 'output_tokens': 28, 'total_tokens': 72}),\n",
       " 'explanation': AIMessage(content='**Joke Explanation: \"The Twisted Spaghetti\"**\\n\\nThe joke is a play on words, using a pun to create humor. Here\\'s a breakdown of the joke:\\n\\n* The setup: \"Why did the spaghetti go to therapy?\" is a typical setup for a joke, asking the listener to think about a situation where spaghetti, a type of food, would need therapy.\\n* The punchline: \"Because it was feeling a little \\'twisted\\' and wanted to untangle its emotions.\" is the humorous part of the joke. Here\\'s what\\'s happening:\\n\\t+ \"Twisted\" has a double meaning:\\n\\t\\t- Spaghetti is literally twisted, as it\\'s a long, curved shape.\\n\\t\\t- \"Twisted\" can also mean emotionally disturbed or upset.\\n\\t+ \"Untangle its emotions\" is a metaphorical expression, suggesting that the spaghetti is trying to resolve its emotional issues.\\n\\nThe joke relies on the wordplay between the literal meaning of \"twisted\" (referring to the shape of spaghetti) and the idiomatic meaning (referring to emotional distress). The punchline creates a clever connection between the setup and the unexpected twist (pun intended!), making it a lighthearted and amusing joke.\\n\\n**Additional Context**\\n\\nThe provided metadata suggests that this joke was generated by a language model (LLaMA 3.1-8b-instant) in response to a user input. The metadata includes information about the model\\'s performance, such as the number of tokens used and the time it took to generate the response. However, this information is not directly relevant to understanding the joke itself.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 332, 'prompt_tokens': 268, 'total_tokens': 600, 'completion_time': 0.543638989, 'completion_tokens_details': None, 'prompt_time': 0.016413652, 'prompt_tokens_details': None, 'queue_time': 0.062781958, 'total_time': 0.560052641}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b546c-bedc-7d90-8741-dac13d0be05d-0', usage_metadata={'input_tokens': 268, 'output_tokens': 332, 'total_tokens': 600})}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config2 = {'configurable' : {'thread_id' : '2'}}\n",
    "final_state2 = workflow.invoke({'topic' : \"Pasta\"}, config = config2)\n",
    "final_state2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c93a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.get_state(config2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cacf609",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(workflow.get_state_history(config2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68274bc",
   "metadata": {},
   "source": [
    "## Simulating crash to check the \"Fault Tolarance\" advantage of Persistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe731d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver\n",
    "from typing import TypedDict\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea7ef1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state\n",
    "class CrashState(TypedDict):\n",
    "\n",
    "      input : str\n",
    "      step1 : str\n",
    "      step2 : str\n",
    "      step3 : str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0b3d2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def step_1(state : CrashState):\n",
    "\n",
    "      print(\"Step - 1 executed\")\n",
    "\n",
    "      return {\"step1\" : \"done\", \"input\" : state['input']}\n",
    "\n",
    "def step_2(state : CrashState):\n",
    "\n",
    "      print(\"Step - 2 hanging..... now manually inturrept\")\n",
    "      time.sleep(30)\n",
    "      return {\"step2\" : \"done\"}\n",
    "\n",
    "def step_3(state : CrashState):\n",
    "\n",
    "      print(\"Step - 3 executed\")\n",
    "\n",
    "      return {\"step3\" : \"done\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dd3db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create graph\n",
    "builder = StateGraph(CrashState)\n",
    "\n",
    "# add_node\n",
    "builder.add_node(\"step_1\", step_1)\n",
    "builder.add_node(\"step_2\", step_2)\n",
    "builder.add_node(\"step_3\", step_3)\n",
    "\n",
    "# add edges\n",
    "builder.add_edge(START, \"step_1\")\n",
    "builder.add_edge(\"step_1\", \"step_2\")\n",
    "builder.add_edge(\"step_2\", \"step_3\")\n",
    "builder.add_edge(\"step_3\", END)\n",
    "\n",
    "# checkpointer\n",
    "checkpointerx = InMemorySaver()\n",
    "\n",
    "# compile\n",
    "workflowx = builder.compile(checkpointer = checkpointerx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b46e9a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(workflowx.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "131b5edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️ Running graph: Please manually interrupt during Step 2...\n",
      "Step - 1 executed\n",
      "Step - 2 hanging..... now manually inturrept\n",
      "❌ Kernel manually interrupted (crash simulated).\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"▶️ Running graph: Please manually interrupt during Step 2...\")\n",
    "    \n",
    "    # Invoking with a thread_id allows you to resume if it crashes/interrupts\n",
    "    workflowx.invoke(\n",
    "        {\"input\": \"Write a post about AI on LinkedIn\"}, \n",
    "        config={\"configurable\": {\"thread_id\": \"thread-1\"}}\n",
    "    )\n",
    "    \n",
    "except KeyboardInterrupt:\n",
    "    print(\"❌ Kernel manually interrupted (crash simulated).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a8001c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'input': 'Write a post about AI on LinkedIn', 'step1': 'done'}, next=('step_2',), config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e166d-4da7-6e7d-8001-4820e5cec89e'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-12-25T07:53:42.248818+00:00', parent_config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e166d-4da5-6777-8000-7e42d746f35e'}}, tasks=(PregelTask(id='346adb9a-47ba-76b6-4272-51c1b46e94d2', name='step_2', path=('__pregel_pull', 'step_2'), error=None, interrupts=(), state=None, result=None),), interrupts=())"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflowx.get_state({\"configurable\": {\"thread_id\": \"thread-1\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e47bde8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'input': 'Write a post about AI on LinkedIn', 'step1': 'done'}, next=('step_2',), config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e166d-4da7-6e7d-8001-4820e5cec89e'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-12-25T07:53:42.248818+00:00', parent_config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e166d-4da5-6777-8000-7e42d746f35e'}}, tasks=(PregelTask(id='346adb9a-47ba-76b6-4272-51c1b46e94d2', name='step_2', path=('__pregel_pull', 'step_2'), error=None, interrupts=(), state=None, result=None),), interrupts=()),\n",
       " StateSnapshot(values={'input': 'Write a post about AI on LinkedIn'}, next=('step_1',), config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e166d-4da5-6777-8000-7e42d746f35e'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-12-25T07:53:42.247819+00:00', parent_config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e166d-4d9e-6225-bfff-8d7344bb5a29'}}, tasks=(PregelTask(id='988341ce-5d36-4867-5782-efac9ff99b4e', name='step_1', path=('__pregel_pull', 'step_1'), error=None, interrupts=(), state=None, result={'step1': 'done', 'input': 'Write a post about AI on LinkedIn'}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e166d-4d9e-6225-bfff-8d7344bb5a29'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-12-25T07:53:42.244816+00:00', parent_config=None, tasks=(PregelTask(id='1a4df0c7-3b91-b397-327d-2c24beb17def', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'input': 'Write a post about AI on LinkedIn'}),), interrupts=())]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflowx.get_state_history({\"configurable\": {\"thread_id\": \"thread-1\"}}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ad63244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step - 2 hanging..... now manually inturrept\n",
      "Step - 3 executed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Write a post about AI on LinkedIn',\n",
       " 'step1': 'done',\n",
       " 'step2': 'done',\n",
       " 'step3': 'done'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# re-run to show fault-tolerance (resume)\n",
    "\n",
    "final_state = workflowx.invoke(\n",
    "        None, \n",
    "        config={\"configurable\": {\"thread_id\": \"thread-1\"}}\n",
    "    )\n",
    "\n",
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "493dbdbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'input': 'Write a post about AI on LinkedIn', 'step1': 'done', 'step2': 'done', 'step3': 'done'}, next=(), config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e1678-2459-61c7-8003-39aa2baf2b5b'}}, metadata={'source': 'loop', 'step': 3, 'parents': {}}, created_at='2025-12-25T07:58:33.196384+00:00', parent_config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e1678-2456-6f47-8002-a9738228ea13'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflowx.get_state({\"configurable\": {\"thread_id\": \"thread-1\"}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4e29817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'input': 'Write a post about AI on LinkedIn', 'step1': 'done', 'step2': 'done', 'step3': 'done'}, next=(), config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e1678-2459-61c7-8003-39aa2baf2b5b'}}, metadata={'source': 'loop', 'step': 3, 'parents': {}}, created_at='2025-12-25T07:58:33.196384+00:00', parent_config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e1678-2456-6f47-8002-a9738228ea13'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'input': 'Write a post about AI on LinkedIn', 'step1': 'done', 'step2': 'done'}, next=('step_3',), config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e1678-2456-6f47-8002-a9738228ea13'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-12-25T07:58:33.195501+00:00', parent_config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e166d-4da7-6e7d-8001-4820e5cec89e'}}, tasks=(PregelTask(id='341bb5bd-940d-8a8f-6639-0595149e5d11', name='step_3', path=('__pregel_pull', 'step_3'), error=None, interrupts=(), state=None, result={'step3': 'done'}),), interrupts=()),\n",
       " StateSnapshot(values={'input': 'Write a post about AI on LinkedIn', 'step1': 'done'}, next=('step_2',), config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e166d-4da7-6e7d-8001-4820e5cec89e'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-12-25T07:53:42.248818+00:00', parent_config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e166d-4da5-6777-8000-7e42d746f35e'}}, tasks=(PregelTask(id='346adb9a-47ba-76b6-4272-51c1b46e94d2', name='step_2', path=('__pregel_pull', 'step_2'), error=None, interrupts=(), state=None, result={'step2': 'done'}),), interrupts=()),\n",
       " StateSnapshot(values={'input': 'Write a post about AI on LinkedIn'}, next=('step_1',), config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e166d-4da5-6777-8000-7e42d746f35e'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-12-25T07:53:42.247819+00:00', parent_config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e166d-4d9e-6225-bfff-8d7344bb5a29'}}, tasks=(PregelTask(id='988341ce-5d36-4867-5782-efac9ff99b4e', name='step_1', path=('__pregel_pull', 'step_1'), error=None, interrupts=(), state=None, result={'step1': 'done', 'input': 'Write a post about AI on LinkedIn'}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': 'thread-1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e166d-4d9e-6225-bfff-8d7344bb5a29'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-12-25T07:53:42.244816+00:00', parent_config=None, tasks=(PregelTask(id='1a4df0c7-3b91-b397-327d-2c24beb17def', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'input': 'Write a post about AI on LinkedIn'}),), interrupts=())]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflowx.get_state_history({\"configurable\": {\"thread_id\": \"thread-1\"}}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c896b12",
   "metadata": {},
   "source": [
    "# Time Travel example execytion - Advantage of Persistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ff2b615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.checkpoint.memory import InMemorySaver   # for taking back the conversation of the previous workflow, it save that in ram\n",
    "from typing import TypedDict, Annotated, Literal\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "64da3fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de98ad32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# state\n",
    "class JokeState(TypedDict):\n",
    "\n",
    "      topic : str\n",
    "      joke : str\n",
    "      explanation : str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6eb4f706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "def generate_joke(state : JokeState):\n",
    "\n",
    "      prompt = f\"generate a joke based on the topic : {state['topic']}\"\n",
    "      response = model.invoke(prompt)\n",
    "\n",
    "      return {\"joke\" : response}\n",
    "\n",
    "def generate_joke_explanation(state : JokeState):\n",
    "\n",
    "      prompt = f\"generate the explanation of this joke : {state['joke']}\"\n",
    "      response = model.invoke(prompt)\n",
    "\n",
    "      return {\"explanation\" : response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a89642d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create graph\n",
    "graph = StateGraph(JokeState)\n",
    "\n",
    "# add_node\n",
    "graph.add_node(\"generate_joke\", generate_joke)\n",
    "graph.add_node(\"generate_joke_explanation\", generate_joke_explanation)\n",
    "\n",
    "# add edges\n",
    "graph.add_edge(START, \"generate_joke\")\n",
    "graph.add_edge(\"generate_joke\", \"generate_joke_explanation\")\n",
    "graph.add_edge(\"generate_joke_explanation\", END)\n",
    "\n",
    "# checkpointer\n",
    "checkpointer = InMemorySaver()\n",
    "\n",
    "# compile\n",
    "workflow = graph.compile(checkpointer = checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "49b15b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "config = {'configurable' : {'thread_id' : '1'}}\n",
    "\n",
    "# working\n",
    "initial_state = {\n",
    "      'topic' : \"Pizza\"\n",
    "}\n",
    "\n",
    "final_state = workflow.invoke(initial_state, config = config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5c40a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'Pizza',\n",
       " 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.028779494, 'completion_tokens_details': None, 'prompt_time': 0.014826652, 'prompt_tokens_details': None, 'queue_time': 0.055606727, 'total_time': 0.043606146}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-201f-7870-a379-388164a71404-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64}),\n",
       " 'explanation': AIMessage(content='**Joke Explanation:**\\n\\nThe joke is a play on words, using a pun to create humor. Here\\'s a breakdown of the joke:\\n\\n- **Setup:** \"Why was the pizza in a bad mood?\"\\n  - This is the setup for the joke, asking the listener to consider why a pizza would be in a bad mood.\\n\\n- **Punchline:** \"Because it was feeling a little crusty.\"\\n  - This is the punchline, providing the answer to the setup. The word \"crusty\" has a double meaning here:\\n    - In one sense, a pizza crust can be crusty, meaning it has a crunchy texture.\\n    - In another sense, \"feeling a little crusty\" is an idiomatic expression meaning feeling a bit irritable or in a bad mood.\\n\\nThe joke relies on this wordplay to create humor. The listener is initially expecting a reason related to the pizza\\'s emotional state, but the punchline subverts this expectation by using the multiple meanings of \"crusty\" to create a clever and amusing connection between the setup and the punchline.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 223, 'prompt_tokens': 257, 'total_tokens': 480, 'completion_time': 0.333423699, 'completion_tokens_details': None, 'prompt_time': 0.015799235, 'prompt_tokens_details': None, 'queue_time': 0.059251765, 'total_time': 0.349222934}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-20cb-7762-a0ec-6bcc7dd7fd49-0', usage_metadata={'input_tokens': 257, 'output_tokens': 223, 'total_tokens': 480})}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "35015cb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={'topic': 'Pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.028779494, 'completion_tokens_details': None, 'prompt_time': 0.014826652, 'prompt_tokens_details': None, 'queue_time': 0.055606727, 'total_time': 0.043606146}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-201f-7870-a379-388164a71404-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64}), 'explanation': AIMessage(content='**Joke Explanation:**\\n\\nThe joke is a play on words, using a pun to create humor. Here\\'s a breakdown of the joke:\\n\\n- **Setup:** \"Why was the pizza in a bad mood?\"\\n  - This is the setup for the joke, asking the listener to consider why a pizza would be in a bad mood.\\n\\n- **Punchline:** \"Because it was feeling a little crusty.\"\\n  - This is the punchline, providing the answer to the setup. The word \"crusty\" has a double meaning here:\\n    - In one sense, a pizza crust can be crusty, meaning it has a crunchy texture.\\n    - In another sense, \"feeling a little crusty\" is an idiomatic expression meaning feeling a bit irritable or in a bad mood.\\n\\nThe joke relies on this wordplay to create humor. The listener is initially expecting a reason related to the pizza\\'s emotional state, but the punchline subverts this expectation by using the multiple meanings of \"crusty\" to create a clever and amusing connection between the setup and the punchline.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 223, 'prompt_tokens': 257, 'total_tokens': 480, 'completion_time': 0.333423699, 'completion_tokens_details': None, 'prompt_time': 0.015799235, 'prompt_tokens_details': None, 'queue_time': 0.059251765, 'total_time': 0.349222934}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-20cb-7762-a0ec-6bcc7dd7fd49-0', usage_metadata={'input_tokens': 257, 'output_tokens': 223, 'total_tokens': 480})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-0e7f-6352-8002-ebe8e868e639'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-12-25T08:31:10.483950+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-0a22-64be-8001-9488f8df64db'}}, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state(config)  # this will show you the final state value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "178bef11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'Pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.028779494, 'completion_tokens_details': None, 'prompt_time': 0.014826652, 'prompt_tokens_details': None, 'queue_time': 0.055606727, 'total_time': 0.043606146}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-201f-7870-a379-388164a71404-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64}), 'explanation': AIMessage(content='**Joke Explanation:**\\n\\nThe joke is a play on words, using a pun to create humor. Here\\'s a breakdown of the joke:\\n\\n- **Setup:** \"Why was the pizza in a bad mood?\"\\n  - This is the setup for the joke, asking the listener to consider why a pizza would be in a bad mood.\\n\\n- **Punchline:** \"Because it was feeling a little crusty.\"\\n  - This is the punchline, providing the answer to the setup. The word \"crusty\" has a double meaning here:\\n    - In one sense, a pizza crust can be crusty, meaning it has a crunchy texture.\\n    - In another sense, \"feeling a little crusty\" is an idiomatic expression meaning feeling a bit irritable or in a bad mood.\\n\\nThe joke relies on this wordplay to create humor. The listener is initially expecting a reason related to the pizza\\'s emotional state, but the punchline subverts this expectation by using the multiple meanings of \"crusty\" to create a clever and amusing connection between the setup and the punchline.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 223, 'prompt_tokens': 257, 'total_tokens': 480, 'completion_time': 0.333423699, 'completion_tokens_details': None, 'prompt_time': 0.015799235, 'prompt_tokens_details': None, 'queue_time': 0.059251765, 'total_time': 0.349222934}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-20cb-7762-a0ec-6bcc7dd7fd49-0', usage_metadata={'input_tokens': 257, 'output_tokens': 223, 'total_tokens': 480})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-0e7f-6352-8002-ebe8e868e639'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-12-25T08:31:10.483950+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-0a22-64be-8001-9488f8df64db'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'Pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.028779494, 'completion_tokens_details': None, 'prompt_time': 0.014826652, 'prompt_tokens_details': None, 'queue_time': 0.055606727, 'total_time': 0.043606146}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-201f-7870-a379-388164a71404-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64})}, next=('generate_joke_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-0a22-64be-8001-9488f8df64db'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-12-25T08:31:10.026463+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-087d-61fd-8000-5a7852195e63'}}, tasks=(PregelTask(id='be8f240d-99bf-197b-453b-213bcaa58faf', name='generate_joke_explanation', path=('__pregel_pull', 'generate_joke_explanation'), error=None, interrupts=(), state=None, result={'explanation': AIMessage(content='**Joke Explanation:**\\n\\nThe joke is a play on words, using a pun to create humor. Here\\'s a breakdown of the joke:\\n\\n- **Setup:** \"Why was the pizza in a bad mood?\"\\n  - This is the setup for the joke, asking the listener to consider why a pizza would be in a bad mood.\\n\\n- **Punchline:** \"Because it was feeling a little crusty.\"\\n  - This is the punchline, providing the answer to the setup. The word \"crusty\" has a double meaning here:\\n    - In one sense, a pizza crust can be crusty, meaning it has a crunchy texture.\\n    - In another sense, \"feeling a little crusty\" is an idiomatic expression meaning feeling a bit irritable or in a bad mood.\\n\\nThe joke relies on this wordplay to create humor. The listener is initially expecting a reason related to the pizza\\'s emotional state, but the punchline subverts this expectation by using the multiple meanings of \"crusty\" to create a clever and amusing connection between the setup and the punchline.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 223, 'prompt_tokens': 257, 'total_tokens': 480, 'completion_time': 0.333423699, 'completion_tokens_details': None, 'prompt_time': 0.015799235, 'prompt_tokens_details': None, 'queue_time': 0.059251765, 'total_time': 0.349222934}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-20cb-7762-a0ec-6bcc7dd7fd49-0', usage_metadata={'input_tokens': 257, 'output_tokens': 223, 'total_tokens': 480})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'Pizza'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-087d-61fd-8000-5a7852195e63'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-12-25T08:31:09.853951+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-087a-6adc-bfff-698921fa21af'}}, tasks=(PregelTask(id='3a01c36a-4e51-04c2-67c2-143b545a3525', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.028779494, 'completion_tokens_details': None, 'prompt_time': 0.014826652, 'prompt_tokens_details': None, 'queue_time': 0.055606727, 'total_time': 0.043606146}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-201f-7870-a379-388164a71404-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-087a-6adc-bfff-698921fa21af'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-12-25T08:31:09.852949+00:00', parent_config=None, tasks=(PregelTask(id='3b2dd515-69fc-4349-3073-7b610c2bded1', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'Pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config))  # code to check all the intermediate value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62387747",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d1a12b69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StateSnapshot(values={}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_id': '1f0e1699-37c8-6909-8000-c64c1e1b945b'}}, metadata=None, created_at=None, parent_config=None, tasks=(), interrupts=())"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.get_state({'configurable' : {'thread_id' : '1', 'checkpoint_id': '1f0e1699-37c8-6909-8000-c64c1e1b945b'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "20c9ec66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'Pizza',\n",
       " 'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.025752211, 'completion_tokens_details': None, 'prompt_time': 0.002041882, 'prompt_tokens_details': None, 'queue_time': 0.065917177, 'total_time': 0.027794093}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-49f7-7563-b328-ec6457fb8af6-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64}),\n",
       " 'explanation': AIMessage(content='Here\\'s an explanation of the joke:\\n\\nThe joke is a play on words. The setup \"Why did the pizza go to the doctor?\" is a common format for a joke, implying that the pizza is going to the doctor for a medical reason. The punchline \"Because it was feeling a little crusty\" is a wordplay on the phrase \"feeling a little crusty,\" which can mean feeling unwell or sick, but in this case, it\\'s also a reference to the crust of a pizza. The crust is a characteristic feature of a pizza, so the joke is making a pun on the word \"crusty\" to create a humorous connection between the pizza\\'s medical issue and its physical composition.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 145, 'prompt_tokens': 261, 'total_tokens': 406, 'completion_time': 0.196012512, 'completion_tokens_details': None, 'prompt_time': 0.015015925, 'prompt_tokens_details': None, 'queue_time': 0.050045245, 'total_time': 0.211028437}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-4a97-7670-9324-fd8f367c4422-0', usage_metadata={'input_tokens': 261, 'output_tokens': 145, 'total_tokens': 406})}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.invoke(initial_state, config = {'configurable' : {'thread_id' : '1', 'checkpoint_id': '1f0e1699-37c8-6909-8000-c64c1e1b945b'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4eb085f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'Pizza', 'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.025752211, 'completion_tokens_details': None, 'prompt_time': 0.002041882, 'prompt_tokens_details': None, 'queue_time': 0.065917177, 'total_time': 0.027794093}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-49f7-7563-b328-ec6457fb8af6-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64}), 'explanation': AIMessage(content='Here\\'s an explanation of the joke:\\n\\nThe joke is a play on words. The setup \"Why did the pizza go to the doctor?\" is a common format for a joke, implying that the pizza is going to the doctor for a medical reason. The punchline \"Because it was feeling a little crusty\" is a wordplay on the phrase \"feeling a little crusty,\" which can mean feeling unwell or sick, but in this case, it\\'s also a reference to the crust of a pizza. The crust is a characteristic feature of a pizza, so the joke is making a pun on the word \"crusty\" to create a humorous connection between the pizza\\'s medical issue and its physical composition.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 145, 'prompt_tokens': 261, 'total_tokens': 406, 'completion_time': 0.196012512, 'completion_tokens_details': None, 'prompt_time': 0.015015925, 'prompt_tokens_details': None, 'queue_time': 0.050045245, 'total_time': 0.211028437}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-4a97-7670-9324-fd8f367c4422-0', usage_metadata={'input_tokens': 261, 'output_tokens': 145, 'total_tokens': 406})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-7341-614a-8002-79eaf7f68f53'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-12-25T08:31:21.049121+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-702e-67bc-8001-c0d2b73e2a7d'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'Pizza', 'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.025752211, 'completion_tokens_details': None, 'prompt_time': 0.002041882, 'prompt_tokens_details': None, 'queue_time': 0.065917177, 'total_time': 0.027794093}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-49f7-7563-b328-ec6457fb8af6-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64})}, next=('generate_joke_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-702e-67bc-8001-c0d2b73e2a7d'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-12-25T08:31:20.726930+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-6ea7-649a-8000-c0e303788709'}}, tasks=(PregelTask(id='a273b6f5-9904-f492-36de-978e30145945', name='generate_joke_explanation', path=('__pregel_pull', 'generate_joke_explanation'), error=None, interrupts=(), state=None, result={'explanation': AIMessage(content='Here\\'s an explanation of the joke:\\n\\nThe joke is a play on words. The setup \"Why did the pizza go to the doctor?\" is a common format for a joke, implying that the pizza is going to the doctor for a medical reason. The punchline \"Because it was feeling a little crusty\" is a wordplay on the phrase \"feeling a little crusty,\" which can mean feeling unwell or sick, but in this case, it\\'s also a reference to the crust of a pizza. The crust is a characteristic feature of a pizza, so the joke is making a pun on the word \"crusty\" to create a humorous connection between the pizza\\'s medical issue and its physical composition.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 145, 'prompt_tokens': 261, 'total_tokens': 406, 'completion_time': 0.196012512, 'completion_tokens_details': None, 'prompt_time': 0.015015925, 'prompt_tokens_details': None, 'queue_time': 0.050045245, 'total_time': 0.211028437}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-4a97-7670-9324-fd8f367c4422-0', usage_metadata={'input_tokens': 261, 'output_tokens': 145, 'total_tokens': 406})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'Pizza'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-6ea7-649a-8000-c0e303788709'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-12-25T08:31:20.566697+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-6ea4-6d8c-bfff-4a7b3d7ed0e8'}}, tasks=(PregelTask(id='4a5ecb3a-6145-d453-d971-ad46e95dbff7', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.025752211, 'completion_tokens_details': None, 'prompt_time': 0.002041882, 'prompt_tokens_details': None, 'queue_time': 0.065917177, 'total_time': 0.027794093}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-49f7-7563-b328-ec6457fb8af6-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-6ea4-6d8c-bfff-4a7b3d7ed0e8'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-12-25T08:31:20.565697+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e1699-37c8-6909-8000-c64c1e1b945b'}}, tasks=(PregelTask(id='7b13f589-51e0-ff93-01a6-653fb77781c8', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'Pizza'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'Pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.028779494, 'completion_tokens_details': None, 'prompt_time': 0.014826652, 'prompt_tokens_details': None, 'queue_time': 0.055606727, 'total_time': 0.043606146}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-201f-7870-a379-388164a71404-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64}), 'explanation': AIMessage(content='**Joke Explanation:**\\n\\nThe joke is a play on words, using a pun to create humor. Here\\'s a breakdown of the joke:\\n\\n- **Setup:** \"Why was the pizza in a bad mood?\"\\n  - This is the setup for the joke, asking the listener to consider why a pizza would be in a bad mood.\\n\\n- **Punchline:** \"Because it was feeling a little crusty.\"\\n  - This is the punchline, providing the answer to the setup. The word \"crusty\" has a double meaning here:\\n    - In one sense, a pizza crust can be crusty, meaning it has a crunchy texture.\\n    - In another sense, \"feeling a little crusty\" is an idiomatic expression meaning feeling a bit irritable or in a bad mood.\\n\\nThe joke relies on this wordplay to create humor. The listener is initially expecting a reason related to the pizza\\'s emotional state, but the punchline subverts this expectation by using the multiple meanings of \"crusty\" to create a clever and amusing connection between the setup and the punchline.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 223, 'prompt_tokens': 257, 'total_tokens': 480, 'completion_time': 0.333423699, 'completion_tokens_details': None, 'prompt_time': 0.015799235, 'prompt_tokens_details': None, 'queue_time': 0.059251765, 'total_time': 0.349222934}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-20cb-7762-a0ec-6bcc7dd7fd49-0', usage_metadata={'input_tokens': 257, 'output_tokens': 223, 'total_tokens': 480})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-0e7f-6352-8002-ebe8e868e639'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-12-25T08:31:10.483950+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-0a22-64be-8001-9488f8df64db'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'Pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.028779494, 'completion_tokens_details': None, 'prompt_time': 0.014826652, 'prompt_tokens_details': None, 'queue_time': 0.055606727, 'total_time': 0.043606146}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-201f-7870-a379-388164a71404-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64})}, next=('generate_joke_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-0a22-64be-8001-9488f8df64db'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-12-25T08:31:10.026463+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-087d-61fd-8000-5a7852195e63'}}, tasks=(PregelTask(id='be8f240d-99bf-197b-453b-213bcaa58faf', name='generate_joke_explanation', path=('__pregel_pull', 'generate_joke_explanation'), error=None, interrupts=(), state=None, result={'explanation': AIMessage(content='**Joke Explanation:**\\n\\nThe joke is a play on words, using a pun to create humor. Here\\'s a breakdown of the joke:\\n\\n- **Setup:** \"Why was the pizza in a bad mood?\"\\n  - This is the setup for the joke, asking the listener to consider why a pizza would be in a bad mood.\\n\\n- **Punchline:** \"Because it was feeling a little crusty.\"\\n  - This is the punchline, providing the answer to the setup. The word \"crusty\" has a double meaning here:\\n    - In one sense, a pizza crust can be crusty, meaning it has a crunchy texture.\\n    - In another sense, \"feeling a little crusty\" is an idiomatic expression meaning feeling a bit irritable or in a bad mood.\\n\\nThe joke relies on this wordplay to create humor. The listener is initially expecting a reason related to the pizza\\'s emotional state, but the punchline subverts this expectation by using the multiple meanings of \"crusty\" to create a clever and amusing connection between the setup and the punchline.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 223, 'prompt_tokens': 257, 'total_tokens': 480, 'completion_time': 0.333423699, 'completion_tokens_details': None, 'prompt_time': 0.015799235, 'prompt_tokens_details': None, 'queue_time': 0.059251765, 'total_time': 0.349222934}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-20cb-7762-a0ec-6bcc7dd7fd49-0', usage_metadata={'input_tokens': 257, 'output_tokens': 223, 'total_tokens': 480})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'Pizza'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-087d-61fd-8000-5a7852195e63'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-12-25T08:31:09.853951+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-087a-6adc-bfff-698921fa21af'}}, tasks=(PregelTask(id='3a01c36a-4e51-04c2-67c2-143b545a3525', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.028779494, 'completion_tokens_details': None, 'prompt_time': 0.014826652, 'prompt_tokens_details': None, 'queue_time': 0.055606727, 'total_time': 0.043606146}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-201f-7870-a379-388164a71404-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-087a-6adc-bfff-698921fa21af'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-12-25T08:31:09.852949+00:00', parent_config=None, tasks=(PregelTask(id='3b2dd515-69fc-4349-3073-7b610c2bded1', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'Pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "641c4fa6",
   "metadata": {},
   "source": [
    "----\n",
    "##### Updating State in between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1863aee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f0e16c4-8d48-683a-8001-eb1bffed16ee'}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.update_state({'configurable' : {'thread_id' : '1', 'checkpoint_id': '1f0e16c1-6ea7-649a-8000-c0e303788709', 'checkpoint_ns': ''}}, {'topic' : 'samosa'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f8a9b6c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'samosa'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c4-8d48-683a-8001-eb1bffed16ee'}}, metadata={'source': 'update', 'step': 1, 'parents': {}}, created_at='2025-12-25T08:32:44.309100+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-6ea7-649a-8000-c0e303788709'}}, tasks=(PregelTask(id='e52b5afe-640f-7e42-cfd3-c2d8e598294a', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result=None),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'Pizza', 'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.025752211, 'completion_tokens_details': None, 'prompt_time': 0.002041882, 'prompt_tokens_details': None, 'queue_time': 0.065917177, 'total_time': 0.027794093}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-49f7-7563-b328-ec6457fb8af6-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64}), 'explanation': AIMessage(content='Here\\'s an explanation of the joke:\\n\\nThe joke is a play on words. The setup \"Why did the pizza go to the doctor?\" is a common format for a joke, implying that the pizza is going to the doctor for a medical reason. The punchline \"Because it was feeling a little crusty\" is a wordplay on the phrase \"feeling a little crusty,\" which can mean feeling unwell or sick, but in this case, it\\'s also a reference to the crust of a pizza. The crust is a characteristic feature of a pizza, so the joke is making a pun on the word \"crusty\" to create a humorous connection between the pizza\\'s medical issue and its physical composition.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 145, 'prompt_tokens': 261, 'total_tokens': 406, 'completion_time': 0.196012512, 'completion_tokens_details': None, 'prompt_time': 0.015015925, 'prompt_tokens_details': None, 'queue_time': 0.050045245, 'total_time': 0.211028437}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-4a97-7670-9324-fd8f367c4422-0', usage_metadata={'input_tokens': 261, 'output_tokens': 145, 'total_tokens': 406})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-7341-614a-8002-79eaf7f68f53'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-12-25T08:31:21.049121+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-702e-67bc-8001-c0d2b73e2a7d'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'Pizza', 'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.025752211, 'completion_tokens_details': None, 'prompt_time': 0.002041882, 'prompt_tokens_details': None, 'queue_time': 0.065917177, 'total_time': 0.027794093}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-49f7-7563-b328-ec6457fb8af6-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64})}, next=('generate_joke_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-702e-67bc-8001-c0d2b73e2a7d'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-12-25T08:31:20.726930+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-6ea7-649a-8000-c0e303788709'}}, tasks=(PregelTask(id='a273b6f5-9904-f492-36de-978e30145945', name='generate_joke_explanation', path=('__pregel_pull', 'generate_joke_explanation'), error=None, interrupts=(), state=None, result={'explanation': AIMessage(content='Here\\'s an explanation of the joke:\\n\\nThe joke is a play on words. The setup \"Why did the pizza go to the doctor?\" is a common format for a joke, implying that the pizza is going to the doctor for a medical reason. The punchline \"Because it was feeling a little crusty\" is a wordplay on the phrase \"feeling a little crusty,\" which can mean feeling unwell or sick, but in this case, it\\'s also a reference to the crust of a pizza. The crust is a characteristic feature of a pizza, so the joke is making a pun on the word \"crusty\" to create a humorous connection between the pizza\\'s medical issue and its physical composition.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 145, 'prompt_tokens': 261, 'total_tokens': 406, 'completion_time': 0.196012512, 'completion_tokens_details': None, 'prompt_time': 0.015015925, 'prompt_tokens_details': None, 'queue_time': 0.050045245, 'total_time': 0.211028437}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-4a97-7670-9324-fd8f367c4422-0', usage_metadata={'input_tokens': 261, 'output_tokens': 145, 'total_tokens': 406})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'Pizza'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-6ea7-649a-8000-c0e303788709'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-12-25T08:31:20.566697+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-6ea4-6d8c-bfff-4a7b3d7ed0e8'}}, tasks=(PregelTask(id='4a5ecb3a-6145-d453-d971-ad46e95dbff7', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.025752211, 'completion_tokens_details': None, 'prompt_time': 0.002041882, 'prompt_tokens_details': None, 'queue_time': 0.065917177, 'total_time': 0.027794093}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-49f7-7563-b328-ec6457fb8af6-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-6ea4-6d8c-bfff-4a7b3d7ed0e8'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-12-25T08:31:20.565697+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e1699-37c8-6909-8000-c64c1e1b945b'}}, tasks=(PregelTask(id='7b13f589-51e0-ff93-01a6-653fb77781c8', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'Pizza'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'Pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.028779494, 'completion_tokens_details': None, 'prompt_time': 0.014826652, 'prompt_tokens_details': None, 'queue_time': 0.055606727, 'total_time': 0.043606146}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-201f-7870-a379-388164a71404-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64}), 'explanation': AIMessage(content='**Joke Explanation:**\\n\\nThe joke is a play on words, using a pun to create humor. Here\\'s a breakdown of the joke:\\n\\n- **Setup:** \"Why was the pizza in a bad mood?\"\\n  - This is the setup for the joke, asking the listener to consider why a pizza would be in a bad mood.\\n\\n- **Punchline:** \"Because it was feeling a little crusty.\"\\n  - This is the punchline, providing the answer to the setup. The word \"crusty\" has a double meaning here:\\n    - In one sense, a pizza crust can be crusty, meaning it has a crunchy texture.\\n    - In another sense, \"feeling a little crusty\" is an idiomatic expression meaning feeling a bit irritable or in a bad mood.\\n\\nThe joke relies on this wordplay to create humor. The listener is initially expecting a reason related to the pizza\\'s emotional state, but the punchline subverts this expectation by using the multiple meanings of \"crusty\" to create a clever and amusing connection between the setup and the punchline.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 223, 'prompt_tokens': 257, 'total_tokens': 480, 'completion_time': 0.333423699, 'completion_tokens_details': None, 'prompt_time': 0.015799235, 'prompt_tokens_details': None, 'queue_time': 0.059251765, 'total_time': 0.349222934}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-20cb-7762-a0ec-6bcc7dd7fd49-0', usage_metadata={'input_tokens': 257, 'output_tokens': 223, 'total_tokens': 480})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-0e7f-6352-8002-ebe8e868e639'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-12-25T08:31:10.483950+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-0a22-64be-8001-9488f8df64db'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'Pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.028779494, 'completion_tokens_details': None, 'prompt_time': 0.014826652, 'prompt_tokens_details': None, 'queue_time': 0.055606727, 'total_time': 0.043606146}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-201f-7870-a379-388164a71404-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64})}, next=('generate_joke_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-0a22-64be-8001-9488f8df64db'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-12-25T08:31:10.026463+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-087d-61fd-8000-5a7852195e63'}}, tasks=(PregelTask(id='be8f240d-99bf-197b-453b-213bcaa58faf', name='generate_joke_explanation', path=('__pregel_pull', 'generate_joke_explanation'), error=None, interrupts=(), state=None, result={'explanation': AIMessage(content='**Joke Explanation:**\\n\\nThe joke is a play on words, using a pun to create humor. Here\\'s a breakdown of the joke:\\n\\n- **Setup:** \"Why was the pizza in a bad mood?\"\\n  - This is the setup for the joke, asking the listener to consider why a pizza would be in a bad mood.\\n\\n- **Punchline:** \"Because it was feeling a little crusty.\"\\n  - This is the punchline, providing the answer to the setup. The word \"crusty\" has a double meaning here:\\n    - In one sense, a pizza crust can be crusty, meaning it has a crunchy texture.\\n    - In another sense, \"feeling a little crusty\" is an idiomatic expression meaning feeling a bit irritable or in a bad mood.\\n\\nThe joke relies on this wordplay to create humor. The listener is initially expecting a reason related to the pizza\\'s emotional state, but the punchline subverts this expectation by using the multiple meanings of \"crusty\" to create a clever and amusing connection between the setup and the punchline.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 223, 'prompt_tokens': 257, 'total_tokens': 480, 'completion_time': 0.333423699, 'completion_tokens_details': None, 'prompt_time': 0.015799235, 'prompt_tokens_details': None, 'queue_time': 0.059251765, 'total_time': 0.349222934}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-20cb-7762-a0ec-6bcc7dd7fd49-0', usage_metadata={'input_tokens': 257, 'output_tokens': 223, 'total_tokens': 480})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'Pizza'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-087d-61fd-8000-5a7852195e63'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-12-25T08:31:09.853951+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-087a-6adc-bfff-698921fa21af'}}, tasks=(PregelTask(id='3a01c36a-4e51-04c2-67c2-143b545a3525', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.028779494, 'completion_tokens_details': None, 'prompt_time': 0.014826652, 'prompt_tokens_details': None, 'queue_time': 0.055606727, 'total_time': 0.043606146}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-201f-7870-a379-388164a71404-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-087a-6adc-bfff-698921fa21af'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-12-25T08:31:09.852949+00:00', parent_config=None, tasks=(PregelTask(id='3b2dd515-69fc-4349-3073-7b610c2bded1', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'Pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2aa6b3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic': 'samosa',\n",
       " 'joke': AIMessage(content='Why did the samosa go to therapy? \\n\\nBecause it was feeling crumby and had a lot of filling issues.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 45, 'total_tokens': 71, 'completion_time': 0.036173208, 'completion_tokens_details': None, 'prompt_time': 0.002866931, 'prompt_tokens_details': None, 'queue_time': 0.050612439, 'total_time': 0.039040139}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a4-516f-7d70-a875-a7f901e47e59-0', usage_metadata={'input_tokens': 45, 'output_tokens': 26, 'total_tokens': 71}),\n",
       " 'explanation': AIMessage(content='**The Joke Explanation**\\n\\nThe joke is a play on words, using a pun to create humor. Here\\'s a breakdown of the joke:\\n\\n- **Setup**: The joke starts with the question, \"Why did the samosa go to therapy?\" This is a common joke structure, where the setup is a question that sets up the expectation for a typical reason why someone might go to therapy (e.g., feeling sad, anxious, etc.).\\n\\n- **Punchline**: The punchline is, \"Because it was feeling crumby and had a lot of filling issues.\" This is where the joke relies on the pun. A samosa is a type of Indian snack that is typically filled with spiced potatoes, peas, and onions. The word \"crumby\" can have a double meaning here - it can mean feeling unwell or unhappy, but it can also refer to the texture of the samosa\\'s crust, which is often crumbly. The phrase \"filling issues\" is also a pun, as it refers to both the emotional issues the samosa is experiencing, but also the fact that a samosa is typically filled with ingredients.\\n\\n- **Humor**: The joke relies on the unexpected twist of using the word \"crumby\" and \"filling issues\" in a way that is both literal and figurative. This play on words creates a sense of surprise and delight, which is the hallmark of a good pun-based joke.\\n\\n**Additional Context**\\n\\nThe provided metadata suggests that the joke was generated by a language model (specifically, the Llama-3.1-8b-instant model) in response to a user input. The metadata includes information about the model\\'s usage, such as the number of tokens used and the time it took to generate the response. However, this information is not directly relevant to understanding the joke itself.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 379, 'prompt_tokens': 267, 'total_tokens': 646, 'completion_time': 0.586254192, 'completion_tokens_details': None, 'prompt_time': 0.01698045, 'prompt_tokens_details': None, 'queue_time': 0.05484666, 'total_time': 0.603234642}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a4-5220-7b72-92c7-a4237d88cc7e-0', usage_metadata={'input_tokens': 267, 'output_tokens': 379, 'total_tokens': 646})}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow.invoke(None, config = {'configurable' : {'thread_id' : '1', 'checkpoint_id': '1f0e16c4-8d48-683a-8001-eb1bffed16ee'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f5058bc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StateSnapshot(values={'topic': 'samosa', 'joke': AIMessage(content='Why did the samosa go to therapy? \\n\\nBecause it was feeling crumby and had a lot of filling issues.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 45, 'total_tokens': 71, 'completion_time': 0.036173208, 'completion_tokens_details': None, 'prompt_time': 0.002866931, 'prompt_tokens_details': None, 'queue_time': 0.050612439, 'total_time': 0.039040139}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a4-516f-7d70-a875-a7f901e47e59-0', usage_metadata={'input_tokens': 45, 'output_tokens': 26, 'total_tokens': 71}), 'explanation': AIMessage(content='**The Joke Explanation**\\n\\nThe joke is a play on words, using a pun to create humor. Here\\'s a breakdown of the joke:\\n\\n- **Setup**: The joke starts with the question, \"Why did the samosa go to therapy?\" This is a common joke structure, where the setup is a question that sets up the expectation for a typical reason why someone might go to therapy (e.g., feeling sad, anxious, etc.).\\n\\n- **Punchline**: The punchline is, \"Because it was feeling crumby and had a lot of filling issues.\" This is where the joke relies on the pun. A samosa is a type of Indian snack that is typically filled with spiced potatoes, peas, and onions. The word \"crumby\" can have a double meaning here - it can mean feeling unwell or unhappy, but it can also refer to the texture of the samosa\\'s crust, which is often crumbly. The phrase \"filling issues\" is also a pun, as it refers to both the emotional issues the samosa is experiencing, but also the fact that a samosa is typically filled with ingredients.\\n\\n- **Humor**: The joke relies on the unexpected twist of using the word \"crumby\" and \"filling issues\" in a way that is both literal and figurative. This play on words creates a sense of surprise and delight, which is the hallmark of a good pun-based joke.\\n\\n**Additional Context**\\n\\nThe provided metadata suggests that the joke was generated by a language model (specifically, the Llama-3.1-8b-instant model) in response to a user input. The metadata includes information about the model\\'s usage, such as the number of tokens used and the time it took to generate the response. However, this information is not directly relevant to understanding the joke itself.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 379, 'prompt_tokens': 267, 'total_tokens': 646, 'completion_time': 0.586254192, 'completion_tokens_details': None, 'prompt_time': 0.01698045, 'prompt_tokens_details': None, 'queue_time': 0.05484666, 'total_time': 0.603234642}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a4-5220-7b72-92c7-a4237d88cc7e-0', usage_metadata={'input_tokens': 267, 'output_tokens': 379, 'total_tokens': 646})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c6-6b4c-659f-8003-87adfe9ec78c'}}, metadata={'source': 'loop', 'step': 3, 'parents': {}}, created_at='2025-12-25T08:33:34.432604+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c6-6494-6af0-8002-772bbd651de4'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'samosa', 'joke': AIMessage(content='Why did the samosa go to therapy? \\n\\nBecause it was feeling crumby and had a lot of filling issues.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 45, 'total_tokens': 71, 'completion_time': 0.036173208, 'completion_tokens_details': None, 'prompt_time': 0.002866931, 'prompt_tokens_details': None, 'queue_time': 0.050612439, 'total_time': 0.039040139}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a4-516f-7d70-a875-a7f901e47e59-0', usage_metadata={'input_tokens': 45, 'output_tokens': 26, 'total_tokens': 71})}, next=('generate_joke_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c6-6494-6af0-8002-772bbd651de4'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-12-25T08:33:33.728228+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c4-8d48-683a-8001-eb1bffed16ee'}}, tasks=(PregelTask(id='2306d02e-dcaa-8c21-c5b5-ccaa56001a9a', name='generate_joke_explanation', path=('__pregel_pull', 'generate_joke_explanation'), error=None, interrupts=(), state=None, result={'explanation': AIMessage(content='**The Joke Explanation**\\n\\nThe joke is a play on words, using a pun to create humor. Here\\'s a breakdown of the joke:\\n\\n- **Setup**: The joke starts with the question, \"Why did the samosa go to therapy?\" This is a common joke structure, where the setup is a question that sets up the expectation for a typical reason why someone might go to therapy (e.g., feeling sad, anxious, etc.).\\n\\n- **Punchline**: The punchline is, \"Because it was feeling crumby and had a lot of filling issues.\" This is where the joke relies on the pun. A samosa is a type of Indian snack that is typically filled with spiced potatoes, peas, and onions. The word \"crumby\" can have a double meaning here - it can mean feeling unwell or unhappy, but it can also refer to the texture of the samosa\\'s crust, which is often crumbly. The phrase \"filling issues\" is also a pun, as it refers to both the emotional issues the samosa is experiencing, but also the fact that a samosa is typically filled with ingredients.\\n\\n- **Humor**: The joke relies on the unexpected twist of using the word \"crumby\" and \"filling issues\" in a way that is both literal and figurative. This play on words creates a sense of surprise and delight, which is the hallmark of a good pun-based joke.\\n\\n**Additional Context**\\n\\nThe provided metadata suggests that the joke was generated by a language model (specifically, the Llama-3.1-8b-instant model) in response to a user input. The metadata includes information about the model\\'s usage, such as the number of tokens used and the time it took to generate the response. However, this information is not directly relevant to understanding the joke itself.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 379, 'prompt_tokens': 267, 'total_tokens': 646, 'completion_time': 0.586254192, 'completion_tokens_details': None, 'prompt_time': 0.01698045, 'prompt_tokens_details': None, 'queue_time': 0.05484666, 'total_time': 0.603234642}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a4-5220-7b72-92c7-a4237d88cc7e-0', usage_metadata={'input_tokens': 267, 'output_tokens': 379, 'total_tokens': 646})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'samosa'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c4-8d48-683a-8001-eb1bffed16ee'}}, metadata={'source': 'update', 'step': 1, 'parents': {}}, created_at='2025-12-25T08:32:44.309100+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-6ea7-649a-8000-c0e303788709'}}, tasks=(PregelTask(id='e52b5afe-640f-7e42-cfd3-c2d8e598294a', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why did the samosa go to therapy? \\n\\nBecause it was feeling crumby and had a lot of filling issues.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 45, 'total_tokens': 71, 'completion_time': 0.036173208, 'completion_tokens_details': None, 'prompt_time': 0.002866931, 'prompt_tokens_details': None, 'queue_time': 0.050612439, 'total_time': 0.039040139}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a4-516f-7d70-a875-a7f901e47e59-0', usage_metadata={'input_tokens': 45, 'output_tokens': 26, 'total_tokens': 71})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'Pizza', 'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.025752211, 'completion_tokens_details': None, 'prompt_time': 0.002041882, 'prompt_tokens_details': None, 'queue_time': 0.065917177, 'total_time': 0.027794093}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-49f7-7563-b328-ec6457fb8af6-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64}), 'explanation': AIMessage(content='Here\\'s an explanation of the joke:\\n\\nThe joke is a play on words. The setup \"Why did the pizza go to the doctor?\" is a common format for a joke, implying that the pizza is going to the doctor for a medical reason. The punchline \"Because it was feeling a little crusty\" is a wordplay on the phrase \"feeling a little crusty,\" which can mean feeling unwell or sick, but in this case, it\\'s also a reference to the crust of a pizza. The crust is a characteristic feature of a pizza, so the joke is making a pun on the word \"crusty\" to create a humorous connection between the pizza\\'s medical issue and its physical composition.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 145, 'prompt_tokens': 261, 'total_tokens': 406, 'completion_time': 0.196012512, 'completion_tokens_details': None, 'prompt_time': 0.015015925, 'prompt_tokens_details': None, 'queue_time': 0.050045245, 'total_time': 0.211028437}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-4a97-7670-9324-fd8f367c4422-0', usage_metadata={'input_tokens': 261, 'output_tokens': 145, 'total_tokens': 406})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-7341-614a-8002-79eaf7f68f53'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-12-25T08:31:21.049121+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-702e-67bc-8001-c0d2b73e2a7d'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'Pizza', 'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.025752211, 'completion_tokens_details': None, 'prompt_time': 0.002041882, 'prompt_tokens_details': None, 'queue_time': 0.065917177, 'total_time': 0.027794093}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-49f7-7563-b328-ec6457fb8af6-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64})}, next=('generate_joke_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-702e-67bc-8001-c0d2b73e2a7d'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-12-25T08:31:20.726930+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-6ea7-649a-8000-c0e303788709'}}, tasks=(PregelTask(id='a273b6f5-9904-f492-36de-978e30145945', name='generate_joke_explanation', path=('__pregel_pull', 'generate_joke_explanation'), error=None, interrupts=(), state=None, result={'explanation': AIMessage(content='Here\\'s an explanation of the joke:\\n\\nThe joke is a play on words. The setup \"Why did the pizza go to the doctor?\" is a common format for a joke, implying that the pizza is going to the doctor for a medical reason. The punchline \"Because it was feeling a little crusty\" is a wordplay on the phrase \"feeling a little crusty,\" which can mean feeling unwell or sick, but in this case, it\\'s also a reference to the crust of a pizza. The crust is a characteristic feature of a pizza, so the joke is making a pun on the word \"crusty\" to create a humorous connection between the pizza\\'s medical issue and its physical composition.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 145, 'prompt_tokens': 261, 'total_tokens': 406, 'completion_time': 0.196012512, 'completion_tokens_details': None, 'prompt_time': 0.015015925, 'prompt_tokens_details': None, 'queue_time': 0.050045245, 'total_time': 0.211028437}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_1151d4f23c', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-4a97-7670-9324-fd8f367c4422-0', usage_metadata={'input_tokens': 261, 'output_tokens': 145, 'total_tokens': 406})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'Pizza'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-6ea7-649a-8000-c0e303788709'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-12-25T08:31:20.566697+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-6ea4-6d8c-bfff-4a7b3d7ed0e8'}}, tasks=(PregelTask(id='4a5ecb3a-6145-d453-d971-ad46e95dbff7', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why did the pizza go to the doctor? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.025752211, 'completion_tokens_details': None, 'prompt_time': 0.002041882, 'prompt_tokens_details': None, 'queue_time': 0.065917177, 'total_time': 0.027794093}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_4387d3edbb', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-49f7-7563-b328-ec6457fb8af6-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-6ea4-6d8c-bfff-4a7b3d7ed0e8'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-12-25T08:31:20.565697+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e1699-37c8-6909-8000-c64c1e1b945b'}}, tasks=(PregelTask(id='7b13f589-51e0-ff93-01a6-653fb77781c8', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'Pizza'}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'Pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.028779494, 'completion_tokens_details': None, 'prompt_time': 0.014826652, 'prompt_tokens_details': None, 'queue_time': 0.055606727, 'total_time': 0.043606146}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-201f-7870-a379-388164a71404-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64}), 'explanation': AIMessage(content='**Joke Explanation:**\\n\\nThe joke is a play on words, using a pun to create humor. Here\\'s a breakdown of the joke:\\n\\n- **Setup:** \"Why was the pizza in a bad mood?\"\\n  - This is the setup for the joke, asking the listener to consider why a pizza would be in a bad mood.\\n\\n- **Punchline:** \"Because it was feeling a little crusty.\"\\n  - This is the punchline, providing the answer to the setup. The word \"crusty\" has a double meaning here:\\n    - In one sense, a pizza crust can be crusty, meaning it has a crunchy texture.\\n    - In another sense, \"feeling a little crusty\" is an idiomatic expression meaning feeling a bit irritable or in a bad mood.\\n\\nThe joke relies on this wordplay to create humor. The listener is initially expecting a reason related to the pizza\\'s emotional state, but the punchline subverts this expectation by using the multiple meanings of \"crusty\" to create a clever and amusing connection between the setup and the punchline.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 223, 'prompt_tokens': 257, 'total_tokens': 480, 'completion_time': 0.333423699, 'completion_tokens_details': None, 'prompt_time': 0.015799235, 'prompt_tokens_details': None, 'queue_time': 0.059251765, 'total_time': 0.349222934}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-20cb-7762-a0ec-6bcc7dd7fd49-0', usage_metadata={'input_tokens': 257, 'output_tokens': 223, 'total_tokens': 480})}, next=(), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-0e7f-6352-8002-ebe8e868e639'}}, metadata={'source': 'loop', 'step': 2, 'parents': {}}, created_at='2025-12-25T08:31:10.483950+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-0a22-64be-8001-9488f8df64db'}}, tasks=(), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'Pizza', 'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.028779494, 'completion_tokens_details': None, 'prompt_time': 0.014826652, 'prompt_tokens_details': None, 'queue_time': 0.055606727, 'total_time': 0.043606146}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-201f-7870-a379-388164a71404-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64})}, next=('generate_joke_explanation',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-0a22-64be-8001-9488f8df64db'}}, metadata={'source': 'loop', 'step': 1, 'parents': {}}, created_at='2025-12-25T08:31:10.026463+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-087d-61fd-8000-5a7852195e63'}}, tasks=(PregelTask(id='be8f240d-99bf-197b-453b-213bcaa58faf', name='generate_joke_explanation', path=('__pregel_pull', 'generate_joke_explanation'), error=None, interrupts=(), state=None, result={'explanation': AIMessage(content='**Joke Explanation:**\\n\\nThe joke is a play on words, using a pun to create humor. Here\\'s a breakdown of the joke:\\n\\n- **Setup:** \"Why was the pizza in a bad mood?\"\\n  - This is the setup for the joke, asking the listener to consider why a pizza would be in a bad mood.\\n\\n- **Punchline:** \"Because it was feeling a little crusty.\"\\n  - This is the punchline, providing the answer to the setup. The word \"crusty\" has a double meaning here:\\n    - In one sense, a pizza crust can be crusty, meaning it has a crunchy texture.\\n    - In another sense, \"feeling a little crusty\" is an idiomatic expression meaning feeling a bit irritable or in a bad mood.\\n\\nThe joke relies on this wordplay to create humor. The listener is initially expecting a reason related to the pizza\\'s emotional state, but the punchline subverts this expectation by using the multiple meanings of \"crusty\" to create a clever and amusing connection between the setup and the punchline.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 223, 'prompt_tokens': 257, 'total_tokens': 480, 'completion_time': 0.333423699, 'completion_tokens_details': None, 'prompt_time': 0.015799235, 'prompt_tokens_details': None, 'queue_time': 0.059251765, 'total_time': 0.349222934}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_f757f4b0bf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-20cb-7762-a0ec-6bcc7dd7fd49-0', usage_metadata={'input_tokens': 257, 'output_tokens': 223, 'total_tokens': 480})}),), interrupts=()),\n",
       " StateSnapshot(values={'topic': 'Pizza'}, next=('generate_joke',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-087d-61fd-8000-5a7852195e63'}}, metadata={'source': 'loop', 'step': 0, 'parents': {}}, created_at='2025-12-25T08:31:09.853951+00:00', parent_config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-087a-6adc-bfff-698921fa21af'}}, tasks=(PregelTask(id='3a01c36a-4e51-04c2-67c2-143b545a3525', name='generate_joke', path=('__pregel_pull', 'generate_joke'), error=None, interrupts=(), state=None, result={'joke': AIMessage(content='Why was the pizza in a bad mood? \\n\\nBecause it was feeling a little crusty.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 44, 'total_tokens': 64, 'completion_time': 0.028779494, 'completion_tokens_details': None, 'prompt_time': 0.014826652, 'prompt_tokens_details': None, 'queue_time': 0.055606727, 'total_time': 0.043606146}, 'model_name': 'llama-3.1-8b-instant', 'system_fingerprint': 'fp_ff2b098aaf', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019b54a2-201f-7870-a379-388164a71404-0', usage_metadata={'input_tokens': 44, 'output_tokens': 20, 'total_tokens': 64})}),), interrupts=()),\n",
       " StateSnapshot(values={}, next=('__start__',), config={'configurable': {'thread_id': '1', 'checkpoint_ns': '', 'checkpoint_id': '1f0e16c1-087a-6adc-bfff-698921fa21af'}}, metadata={'source': 'input', 'step': -1, 'parents': {}}, created_at='2025-12-25T08:31:09.852949+00:00', parent_config=None, tasks=(PregelTask(id='3b2dd515-69fc-4349-3073-7b610c2bded1', name='__start__', path=('__pregel_pull', '__start__'), error=None, interrupts=(), state=None, result={'topic': 'Pizza'}),), interrupts=())]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(workflow.get_state_history(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dceb3a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GAIP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
